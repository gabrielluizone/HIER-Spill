{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **AI Research Scientit**\n",
    "> **[``2024-07-24``]() $\\rightarrow$ [``2025-06-26``]()**\n",
    "\n",
    "```{Python}\n",
    "- Tech Lead :: Gabriel L. S. Silva\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from HIERColect import OverColetor\n",
    "from datetime import datetime\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import geocoder\n",
    "import logging\n",
    "import base64\n",
    "import time\n",
    "import json\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = requests.get(\"https://raw.githubusercontent.com/gabrielluizone/FirstCode/refs/heads/main/conn.key\").text.strip()\n",
    "g = geocoder.ip('me')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OverColetor:\n",
    "    def __init__(self, empresa_id, empresa_nome, coletor_id, coletor_descricao, coletor_localizacao,\n",
    "                 camera_source=0, model_key=\"oil_spill\", model_path=\"models/Vo1.pt\", show_notebook=True,\n",
    "                 capture_interval=15, confidence_threshold=0.7, ngrok_domain=\"\"):\n",
    "        \"\"\"Inicializa o detector de manchas de óleo - versão corrigida\"\"\"\n",
    "        \n",
    "        # Configurações básicas\n",
    "        self.EMPRESA_ID = empresa_id\n",
    "        self.EMPRESA_NOME = empresa_nome\n",
    "        self.COLETOR_ID = coletor_id\n",
    "        self.MODELO_ID = model_key\n",
    "        self.COLETOR_DESCRICAO = coletor_descricao\n",
    "        self.COLETOR_LOCALIZACAO = coletor_localizacao\n",
    "        \n",
    "        # Configurações de operação\n",
    "        self.CAPTURE_INTERVAL_SECONDS = capture_interval\n",
    "        self.CONFIDENCE_THRESHOLD = confidence_threshold\n",
    "        self.CAMERA_SOURCE = camera_source\n",
    "        self.SHOW_NOTEBOOK = show_notebook\n",
    "        \n",
    "        # URLs do servidor - CORRIGIDO\n",
    "        base_url = f\"https://{ngrok_domain}.ngrok-free.app\"\n",
    "        self.OIL_DETECTION_URL = f\"{base_url}/oil_detection\"  # Endpoint correto\n",
    "        self.SKF_ANALYSIS_URL = f\"{base_url}/skf_analysis\"\n",
    "        self.HEALTH_URL = f\"{base_url}/health\"\n",
    "        \n",
    "        # Caminho do modelo\n",
    "        self.MODEL_PATH = model_path\n",
    "        \n",
    "        # Configurar log básico\n",
    "        self._setup_logger()\n",
    "        \n",
    "        # Testar conexão na inicialização\n",
    "        self._test_server_connection()\n",
    "        \n",
    "    def _setup_logger(self):\n",
    "        \"\"\"Configura log básico\"\"\"\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "        )\n",
    "        self.logger = logging.getLogger('OverColetor')\n",
    "    \n",
    "    def _test_server_connection(self):\n",
    "        \"\"\"Testa conexão com o servidor\"\"\"\n",
    "        try:\n",
    "            response = requests.get(self.HEALTH_URL, timeout=10)\n",
    "            if response.ok:\n",
    "                health_data = response.json()\n",
    "                self.logger.info(f\"✓ Servidor conectado: {health_data.get('status', 'unknown')}\")\n",
    "                return True\n",
    "            else:\n",
    "                self.logger.error(f\"✗ Servidor não respondeu adequadamente: {response.status_code}\")\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"✗ Erro ao conectar com servidor: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def _encode_image_high_quality(self, image):\n",
    "        \"\"\"Codifica imagem em base64 mantendo alta qualidade\"\"\"\n",
    "        try:\n",
    "            # Usar PNG com compressão mínima para manter qualidade\n",
    "            encode_params = [cv2.IMWRITE_PNG_COMPRESSION, 1]  # Compressão mínima (0-9, onde 0=sem compressão)\n",
    "            success, buffer = cv2.imencode('.png', image, encode_params)\n",
    "            \n",
    "            if not success:\n",
    "                raise ValueError(\"Falha ao codificar imagem\")\n",
    "            \n",
    "            # Converter para base64\n",
    "            image_b64 = base64.b64encode(buffer).decode('utf-8')\n",
    "            \n",
    "            # Log do tamanho para debug\n",
    "            size_mb = len(image_b64) * 3/4 / (1024*1024)  # Aproximação do tamanho em MB\n",
    "            #self.logger.debug(f\"Imagem codificada: {size_mb:.2f}MB\")\n",
    "            \n",
    "            return image_b64\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Erro ao codificar imagem: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def _send_data_to_server(self, original_image, processed_image, detection_data, metadata):\n",
    "        \"\"\"Envia dados para o servidor usando o endpoint correto\"\"\"\n",
    "        try:\n",
    "            # Codificar imagens em base64 com alta qualidade\n",
    "            #self.logger.info(\"Codificando imagens...\")\n",
    "            imagem_original_b64 = self._encode_image_high_quality(original_image)\n",
    "            imagem_processada_b64 = self._encode_image_high_quality(processed_image)\n",
    "            \n",
    "            if not imagem_original_b64 or not imagem_processada_b64:\n",
    "                self.logger.error(\"Falha na codificação das imagens\")\n",
    "                return False\n",
    "            \n",
    "            # Criar timestamp ISO format\n",
    "            now = datetime.now()\n",
    "            timestamp_iso = now.isoformat()\n",
    "            timestamp_file = now.strftime('%Y%m%d_%H%M%S_%f')[:-3]  # Formato para nome do arquivo\n",
    "            detections_count = len(detection_data)\n",
    "            \n",
    "            # Nomes dos arquivos\n",
    "            original_image_name = f\"RAW-{self.EMPRESA_ID}-{self.COLETOR_ID}-{self.MODELO_ID}-{timestamp_file}-{detections_count}.png\"\n",
    "            processed_image_name = f\"PRC-{self.EMPRESA_ID}-{self.COLETOR_ID}-{self.MODELO_ID}-{timestamp_file}-{detections_count}.png\"\n",
    "            \n",
    "            # Preparar payload conforme esperado pelo servidor\n",
    "            payload = {\n",
    "                \"imagem_original_base64\": imagem_original_b64,\n",
    "                \"imagem_processada_base64\": imagem_processada_b64,\n",
    "                \"name_imagem_original\": original_image_name,\n",
    "                \"name_imagem_processada\": processed_image_name,\n",
    "                \"empresa_info\": {\n",
    "                    \"empresa_id\": self.EMPRESA_ID,\n",
    "                    \"empresa_nome\": self.EMPRESA_NOME,\n",
    "                    \"coletor_id\": self.COLETOR_ID,\n",
    "                    \"modelo_id\": self.MODELO_ID,\n",
    "                    \"coletor_descricao\": self.COLETOR_DESCRICAO,\n",
    "                    \"localizacao\": self.COLETOR_LOCALIZACAO\n",
    "                },\n",
    "                \"detection_data\": detection_data,\n",
    "                \"metadata\": metadata,\n",
    "                \"timestamp\": timestamp_iso,  # ISO format para timestamp\n",
    "                \"confidence_threshold\": max([d['confidence'] for d in detection_data]) if detection_data else self.CONFIDENCE_THRESHOLD,\n",
    "                \"detections_count\": detections_count\n",
    "            }\n",
    "            \n",
    "            # Log do tamanho do payload\n",
    "            payload_size_mb = len(json.dumps(payload).encode('utf-8')) / (1024*1024)\n",
    "            self.logger.info(f\"Enviando payload de {payload_size_mb:.2f}MB com {detections_count} detecções...\")\n",
    "            \n",
    "            # Headers adequados\n",
    "            headers = {\n",
    "                'Content-Type': 'application/json',\n",
    "                'Accept': 'application/json'\n",
    "            }\n",
    "            \n",
    "            # Enviar dados com timeout maior para imagens grandes\n",
    "            response = requests.post(\n",
    "                self.OIL_DETECTION_URL, \n",
    "                json=payload, \n",
    "                headers=headers,\n",
    "                timeout=60  # Timeout maior para imagens de alta qualidade\n",
    "            )\n",
    "            \n",
    "            # Log da resposta completa para debug\n",
    "            self.logger.info(f\"Status da resposta: {response.status_code}\")\n",
    "            \n",
    "            if response.ok:\n",
    "                try:\n",
    "                    result = response.json()\n",
    "                    self.logger.debug(f\"Resposta do servidor: {result}\")\n",
    "                    \n",
    "                    # Verificar se foi processado com sucesso\n",
    "                    if result.get(\"status\") == \"success\" or result.get(\"return\") == 1:\n",
    "                        deteccao_id = result.get(\"deteccao_id\")\n",
    "                        self.logger.info(f\"✓ Captura & Dados Enviados :: ID {deteccao_id}\")\n",
    "                        return True\n",
    "                    else:\n",
    "                        self.logger.warning(f\"✗ Servidor não confirmou sucesso: {result}\")\n",
    "                        return False\n",
    "                        \n",
    "                except json.JSONDecodeError:\n",
    "                    self.logger.error(f\"✗ Resposta inválida do servidor: {response.text}\")\n",
    "                    return False\n",
    "            else:\n",
    "                self.logger.error(f\"✗ Erro HTTP {response.status_code}: {response.text}\")\n",
    "                return False\n",
    "                \n",
    "        except requests.exceptions.Timeout:\n",
    "            self.logger.error(\"✗ Timeout ao enviar dados (imagem muito grande?)\")\n",
    "            return False\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            self.logger.error(\"✗ Erro de conexão com servidor\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"✗ Erro ao enviar dados: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def _detect_and_send(self):\n",
    "        \"\"\"Captura imagem, executa detecção e envia dados\"\"\"\n",
    "        try:\n",
    "            # Carregar modelo\n",
    "            self.logger.debug(\"Carregando modelo YOLO...\")\n",
    "            model = YOLO(self.MODEL_PATH, verbose=False)\n",
    "            \n",
    "            # Capturar imagem da câmera\n",
    "            self.logger.debug(\"Capturando imagem da câmera...\")\n",
    "            cap = cv2.VideoCapture(self.CAMERA_SOURCE)\n",
    "            \n",
    "            # Configurar resolução máxima da câmera (opcional)\n",
    "            cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)\n",
    "            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)\n",
    "            \n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                cap.release()\n",
    "                raise ValueError(\"Não foi possível capturar imagem da câmera\")\n",
    "            \n",
    "            original_image = frame.copy()\n",
    "            cap.release()\n",
    "            \n",
    "            #self.logger.info(f\"Imagem capturada: {original_image.shape[1]}x{original_image.shape[0]}\")\n",
    "            \n",
    "            # Executar detecção\n",
    "            self.logger.debug(\"Executando detecção YOLO...\")\n",
    "            results = model(original_image, conf=self.CONFIDENCE_THRESHOLD, verbose=False)\n",
    "            \n",
    "            # Processar resultados\n",
    "            detections = []\n",
    "            for result in results:\n",
    "                for box in result.boxes:\n",
    "                    detections.append({\n",
    "                        'class': result.names[int(box.cls)],\n",
    "                        'confidence': round(float(box.conf), 6),  # Mais precisão\n",
    "                        'bbox': [round(coord, 2) for coord in box.xyxy[0].tolist()],\n",
    "                        'bbox_normalized': [round(coord, 6) for coord in box.xywhn[0].tolist()]  # Coordenadas normalizadas\n",
    "                    })\n",
    "            \n",
    "            #self.logger.info(f\"Detecções encontradas: {len(detections)}\")\n",
    "            \n",
    "            # Se não há detecções, apenas log (não enviar)\n",
    "            if len(detections) == 0:\n",
    "                #self.logger.info(\"Nenhuma detecção encontrada - não enviando\")\n",
    "                return False\n",
    "            \n",
    "            # Gerar imagem com detecções\n",
    "            processed_image = results[0].plot()\n",
    "            \n",
    "            # Mostrar imagens se solicitado\n",
    "            if self.SHOW_NOTEBOOK:\n",
    "                self._display_results(original_image, processed_image, detections)\n",
    "            \n",
    "            # Criar metadados mais detalhados\n",
    "            metadata = {\n",
    "                'model_info': {\n",
    "                    'model_path': self.MODEL_PATH,\n",
    "                    'confidence_threshold': self.CONFIDENCE_THRESHOLD\n",
    "                },\n",
    "                'image_info': {\n",
    "                    'original_shape': original_image.shape,\n",
    "                    'channels': original_image.shape[2] if len(original_image.shape) > 2 else 1\n",
    "                },\n",
    "                'inference_speed': {\n",
    "                    'preprocess_ms': round(results[0].speed['preprocess'], 4),\n",
    "                    'inference_ms': round(results[0].speed['inference'], 4),\n",
    "                    'postprocess_ms': round(results[0].speed['postprocess'], 4)\n",
    "                },\n",
    "                'detection_summary': {\n",
    "                    'total_detections': len(detections),\n",
    "                    'max_confidence': max([d['confidence'] for d in detections]) if detections else 0,\n",
    "                    'classes_detected': list(set([d['class'] for d in detections]))\n",
    "                },\n",
    "                'timestamp_capture': datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            # Enviar dados\n",
    "            send_success = self._send_data_to_server(original_image, processed_image, detections, metadata)\n",
    "            \n",
    "            return send_success\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Erro na detecção: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def _display_results(self, original_image, processed_image, detections):\n",
    "        \"\"\"Exibe resultados da detecção\"\"\"\n",
    "        try:\n",
    "            original_rgb = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "            processed_rgb = cv2.cvtColor(processed_image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            plt.figure(figsize=(15, 6))\n",
    "            \n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(original_rgb)\n",
    "            plt.title('Imagem Original')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(processed_rgb)\n",
    "            plt.title(f'Detecções ({len(detections)} encontradas)')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Adicionar lista de detecções\n",
    "            detection_text = \"\\n\".join([\n",
    "                f\"{d['class']}: {d['confidence']:.3f}\" for d in detections[:5]  # Mostrar apenas 5 primeiras\n",
    "            ])\n",
    "            if len(detections) > 5:\n",
    "                detection_text += f\"\\n... e mais {len(detections)-5}\"\n",
    "            \n",
    "            plt.figtext(0.02, 0.02, detection_text, fontsize=8, verticalalignment='bottom')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.warning(f\"Erro ao exibir resultados: {str(e)}\")\n",
    "    \n",
    "    def test_single_detection(self):\n",
    "        \"\"\"Executa uma única detecção para teste\"\"\"\n",
    "        self.logger.info(\"=== TESTE DE DETECÇÃO ÚNICA ===\")\n",
    "        success = self._detect_and_send()\n",
    "        if success:\n",
    "            self.logger.info(\"✓ Teste concluído com sucesso!\")\n",
    "        else:\n",
    "            self.logger.warning(\"✗ Teste falhou!\")\n",
    "        return success\n",
    "    \n",
    "    def run_continuous_monitoring(self):\n",
    "        \"\"\"Executa monitoramento contínuo\"\"\"\n",
    "        #self.logger.info(\"=== INICIANDO MONITORAMENTO CONTÍNUO ===\")\n",
    "        self.logger.info(f\"Empresa: {self.EMPRESA_NOME} ({self.EMPRESA_ID})\")\n",
    "        self.logger.info(f\"Coletor: {self.COLETOR_DESCRICAO} ({self.COLETOR_ID})\")\n",
    "        self.logger.info(f\"Intervalo: {self.CAPTURE_INTERVAL_SECONDS}s\")\n",
    "        self.logger.info(f\"Confiança: {self.CONFIDENCE_THRESHOLD}\")\n",
    "        \n",
    "        successful_sends = 0\n",
    "        total_attempts = 0\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                total_attempts += 1\n",
    "                #self.logger.info(f\"\\n--- Captura #{total_attempts} ---\")\n",
    "                \n",
    "                success = self._detect_and_send()\n",
    "                if success:\n",
    "                    successful_sends += 1\n",
    "                \n",
    "                success_rate = (successful_sends / total_attempts) * 100\n",
    "                #self.logger.info(f\"Taxa de sucesso: {successful_sends}/{total_attempts} ({success_rate:.1f}%)\")\n",
    "                \n",
    "                # Aguardar próxima captura\n",
    "                if self.CAPTURE_INTERVAL_SECONDS > 0:\n",
    "                    #self.logger.info(f\"Aguardando {self.CAPTURE_INTERVAL_SECONDS}s...\")\n",
    "                    time.sleep(self.CAPTURE_INTERVAL_SECONDS)\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            #self.logger.info(f\"\\n=== MONITORAMENTO INTERROMPIDO ===\")\n",
    "            self.logger.info(f\"Total de tentativas: {total_attempts}\")\n",
    "            self.logger.info(f\"Envios bem-sucedidos: {successful_sends}\")\n",
    "            self.logger.info(f\"Taxa de sucesso final: {success_rate:.1f}%\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Erro no monitoramento: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coletor = OverColetor(\n",
    "    empresa_id='DEMO001',\n",
    "    empresa_nome='Demonstracao',\n",
    "    coletor_id='DMO005',\n",
    "    coletor_descricao='Camera Teste - CENEP',\n",
    "    coletor_localizacao=f'{g.latlng[0]}, {g.latlng[1]}' if g.latlng else  '-23.9931, -46.2564',\n",
    "    camera_source=0,\n",
    "    model_key=\"OilSpill\",\n",
    "    model_path=\"models/Vo1.pt\",\n",
    "    show_notebook=True,\n",
    "    capture_interval=7,\n",
    "    confidence_threshold=0.7,\n",
    "    ngrok_domain=key\n",
    ")\n",
    "coletor.run_continuous_monitoring()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
